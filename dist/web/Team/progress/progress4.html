<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!--
This is an example weekly progress report document that team members can use to report their individual progress 
of their ECE477 senior design projects. Weekly progress reports are expected to follow the general guidelines
presented in the "Progress Report Policy" document, posted on Brightspace.  

Please create 4 copies of this example, renaming each copy to <PurdueID>.html, where <PurdueID> corresponds to
the Purdue ITAP Career Account ID given by Purdue to each individual team member. If you have any questions,
contact course staff.
-->
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

<!--Reconfigurable base tag; used to modify the site root location for root-relative links-->
<!--<base href="https://engineering.purdue.edu/ece477/StudentWebTemplate/" />-->
    <base href="https://engineering.purdue.edu/477grp2/" /> <!-- Replace the N with your team number-->

<!--Content-->
<title>ECE477 Course Documents</title>
<meta name="keywords" content="" />
<meta name="description" content="" />
<meta name="author" content="George Hadley">
<meta name = "format-detection" content = "telephone=no" />
<meta name="viewport" content="width=device-width,initial-scale=1.0">

<!--CSS-->
<link rel="stylesheet" href="css/default.css" type="text/css" media="all" />
<link rel="stylesheet" href="css/responsive.css">
<link rel="stylesheet" href="css/styles.css">
<link rel="stylesheet" href="css/content.css">
<link rel="stylesheet" href ="css/bradenPage.css">
<!--[if IE 6]>
<link href="default_ie6.css" rel="stylesheet" type="text/css" />
<![endif]-->

</head>
<body>
<div id="wrapper_site">
    <div id="wrapper_page">
	<!-- Instantiate global site header.-->
	<div id="header"></div>
		<!-- Instantiate site global navigation bar.-->
		<div id="menu"></div>
	
		<!-- Instantiate a page banner image. Page banner images should be 1100x350px and should be located within the local
			img folder located at this directory level. -->
		<div id="banner">
			<img src="Files/img/BannerImgExample.jpg"></img>
		</div>
	
		<!-- Instantiate "tools" needed for a page. Tools are premade functional blocks that can be used to build a page,
			and include things such as a file lister (for listing out homework assignments or tutorials)
		-->
		<div id="content">

		<h2>Progress Report/Engineering Project Journal for Braden Kirkendall</h2>
		<b>Total Hours: 132.50 </b>

		<hr> <h1> Week 15 </h1> <b>Hours this week: 20.25</b>  </b><hr> 

		<b>Date Reported: 04/19/2024 </b> <br>
		<b>Start Time:</b> 10:30 am <br>
		<b>Work Time:</b> 1.00 hours <br>
		<ul>
			<li>I came into lab to record the documentation for this weeks journal</li>
		</ul>
		<hr>

		<b>Date Reported: 04/17/2024 </b> <br>
		<b>Start Time:</b> 8:30 am <br>
		<b>Work Time:</b> 2.25 hours <br>
		<ul>
			<li> I completed the ABET draft and reviewed it for submission. When finalized, it will be available on this website under the documents tab. </li>
		</ul>
		<hr>

		<b>Date Reported: 04/16/2024 </b> <br>
		<b>Start Time:</b> 8:00 pm <br>
		<b>Work Time:</b> 2.00 hours <br>
		<ul>
			<li> I picked up work where I left off on the ABET document. In culmination I completed a majority of the shared sections since I was not 
				in town over the weekend and unable to come into lab to help during the saturday work session.
			</li>
		</ul>
		<hr>

		<b>Date Reported: 04/16/2024 </b> <br>
		<b>Start Time:</b> 1:00 pm <br>
		<b>Work Time:</b> 3.00 hours <br>
		<ul>
			<li>
				I arrived a little bit before the rest of the team to add the final touches to the packaging including removing two of the pegs that we orginally had and adding 
				velco to make the panel removable. This is likely better understood in a visual.
				<br><img src="Team/progress/img - member4/w15i3.png" width="500" height="500" /></img> 
				<figcaption>Figure 48. Image of Velco on Packaging</figcaption>	
			</li>
			<li>
				We had our final demo scheduled and expected the MOUSE to exhibit the same behavior as it had when we successfully tested previously. However, we once again encountered an 
				issue where the micro was not pulling power. 
			</li>
			<li>
				While it accounted for a significant amount of time, I don't have a lot to say about the actual debugging process. We analyzed the potential difference across many of the vias 
				and found expected results. We tried removing the board from the packaging, discharging the capacitors, removing dust/liquid with the compressed air all to no avail. Eventually, the 
				board started pulling sufficient current again and was able to be flashed. We don't have a good explanation as to why this behavior is displayed. However, once it started to work we 
				were able to demo successfully.
			</li>
			<li>
				Following the demo, we cleaned up our lab station and organized the parts that we wanted to donate back to the lab.
			</li>
		</ul>
		<hr>



		<b>Date Reported: 04/15/2024 </b> <br>
		<b>Start Time:</b> 8:00 pm <br>
		<b>Work Time:</b> 0.5 hours <br>
		<ul>
			<li>I needed to take a trip to the store to get velcro to finish off our packaging so that the final piece could be easily removed and provide access to 
				the board and various electrical components.
			</li>
		</ul>
		<hr>

		<b>Date Reported: 04/15/2024 </b> <br>
		<b>Start Time:</b> 1:00 pm <br>
		<b>Work Time:</b> 5.00 hours <br>
		<ul>
			<li>The first couse of action for this work session was to ensure that the newly-soldered micro was exhibiting the correct behavior on the PCB. We initially 
				ran into a software issue that Matt and I worked on debugging where the project was not building successfully. After some head-banging it was determined that 
				a solution was to create a new example repository and copy our existing code into that to test it. I don't fully know why this works but it is likely that
				the configuration files for the build process were accidentally changed.
			</li>
			<li>
				Since the PIR sensor was a known problem that shorted the last time it was connected, we performed thorough validation that it was reconnected in a correct orientation. While
				the actual component only has pins, we could not afford to lose another micro. I think I validated our design with the online documentation at least 3 or 4 times to be thorough.
			</li>
			<li>
				Additionally, it was decided that for demonstration purposes it might be most effective to move the scanning mechanism to be a toggle within the user dashboard. This could also allow
				more fine-grained control from the user while attempting to record a series of actions. This consisted of adding the "gs" endpoint to get the scannning state and recieve it on the microcontroller 
				according to the value in the locally-stored api. This new endpoint is shown below.
				<br><img src="Team/progress/img - member4/w15i1.png" width="700" height="500" /></img> 
				<figcaption>Figure 46. Image of gs Socket Endpoint for Scan Toggle</figcaption>	
			</li>
			<li>
				After the motor driver was successfully soldered onto our board, we were ready to test all of our functionality. However, we encountered extremely weird behavior that we 
				don't currently have an explanation for. The micro stopped pulling sufficient power and we assumed that it had been fried. Even after collaborations with the course staff, we 
				were confident that the chip had been fried since this seemed to be the only explanation for the behavior we were experiencing. However, after about 20-30 minutes of probing and debugging 
				of the system for damage control, the chip randomly started pulling enough power to connect to and flash. We were able to test all of the features and experienced success. At the time, 
				I was ready to chalk up this behavior to liquids or dirt that needed to dry but as I later experienced this didn't seem to be the case.
				<br><img src="Team/progress/img - member4/w15i2.png" width="700" height="700" /></img> 
				<figcaption>Figure 47. Image of Functionality Testing</figcaption>	

			</li>	
			<li>
				At this time we also spray painted some of the outside of the MOUSE to add to the quality of the packaging.
			</li>
		</ul>
		<hr>

		<b>Date Reported: 04/15/2024 </b> <br>
		<b>Start Time:</b> 9:30 am <br>
		<b>Work Time:</b> 1.50 hours <br>
		<ul>
			<li> I met with Matt and Andrew to verify with Joe our assumptions about the board that the ESP chip was shorted and the best means to progress.</li>
			<li> We agreed that the ESP was probably shorted and proceeded with the replacement process of desoldering the old one and soldering a new one. One key piece of 
				advice that we followed was to use a liberal amount of alcohol. However, this meant that we had to wait a few hours after to come back and test the results.
			</li>
		</ul>
		<hr>

		<b>Date Reported: 04/14/2024 </b> <br>
		<b>Start Time:</b> 7:00 pm <br>
		<b>Work Time:</b> 5.00 hours <br>
		<ul>
			<li> I caught up with the progress that the team had made on the MOUSE for movement and verified their results with the expected output from the code.</li>
			<li> During this work session, I collaborated with the rest of the team to determine the functionality of the PCB after we caused a short with the PIR sensor. The 
				entire board stopped becoming recognizable as a port to flash to and it became a major hardware concern. Throughout this process many of the components were tested and didn't 
				seem to be working as intended. At this point we thought that the ESP was shorted and so we went through the tedious process of removing it and resoldering on a new one. However, 
				since this was our last ESP32S3 chip, we also had to be extra careful that there were no other issues with the board causing the chip to be fried so that this behavior wasn't repeated. 
			</li>
			<li>We had a lot of debugging to do with the probes available in the lab to determine which parts of the board were damaged beyond repair. I aided in this debugging but also was validating the path 
				recording functionality in the meantime. There were some bugs in the newest implementation where calls to the frontend were no longer invoking some of the key endpoints that I had set up for the 
				recording and playback states. This resulted in both the UI and the backend logic being incorrect. One issue that I fixed was that the recording file data was not actually being transmitted, a followup 
				issue was also that the UI on the dashboard could get erroneously stuck in the playback or recording states without the ability to leave. All of these issues were solved by analyzing differences between 
				the older version of the code with working features and ensuring that the same socket endpoints were hit to provide feedback from the backend for status updates and fetching recording data. 
			</li>
			<li>
				An additional piece of progress was finishing out the last part of the packaging from the 3d printed materials. Here is an image of two of the pieces that I glued together to 
				form the access hatch that we want to velcro on for easy access.
				<br><img src="Team/progress/img - member4/w15i4.png" width="500" height="500" /></img> 
				<figcaption>Figure 45. Image of 3d Printed Part Connections</figcaption>	
			</li>
		</ul>


		<hr> <h1> Week 14 </h1> <b>Hours this week: 8.75</b>  </b><hr> 
		<b>Date Reported: 04/12/2024 </b> <br>
		<b>Start Time:</b> 8:00 am <br>
		<b>Work Time:</b> 2.50 hours <br>
		<ul>
			<li>Continued working on ABET design report.</li>
			<li>Recorded entries in lab notebook.</li>
		</ul>
		<hr>

		<b>Date Reported: 04/11/2024 </b> <br>
		<b>Start Time:</b> 2:30 pm <br>
		<b>Work Time:</b> 1.50 hours <br>
		<ul>
			<li>Started planning and drafting responses for the ABET design report.</li>
		</ul>
		<hr>

		<b>Date Reported: 04/10/2024 </b> <br>
		<b>Start Time:</b> 3:20 pm <br>
		<b>Work Time:</b> 2.75 hours <br>
		<ul>
			<li>I briefly worked on packaging as another 3d printed component was ready to be placed in. I also went around the outside of the packaging and tried to remove 
				spots with noticable buildup of glue now that the general structural integrity of the build was secured. </li>
			<li>
				I worked with the team to theorize how we could orient the stepper with a slip ring for full 360-degree rotation on top of the packaging. We ended up determining a system 
				where the stepper actually sits atop a rod that it spins. This rod then houses the PIR sensor. To make sure that the geometry worked out I modeled the system with a wooden rod 
				that we had and it seemed to work without issue sitting atop the packaging.
			</li>
			<li>
				We needed to attach the chassis to the outer shell and to do so we fit zipties through grating that aligned the 3d printed parts and the metal chassis. Shown is an image of this attachment process.
				I was dubious of how sturdy this would be but after testing force applications it held quite well.
				<br><img src="Team/progress/img - member4/w14i3.png" width="500" height="500" /></img> 
				<figcaption>Figure 44. Images of Chassis-Shell Connection with Zipties</figcaption>	
			</li>
			<li>
				Additionally, I used the dremmel to shave down the connecting pegs between the top and bottom parts of the shell so that they actually fit.
			</li>
			<li>
				In addition I reviewed the code and created some global parameters that could be easily adjusted for drive calibration.
			</li>
		</ul>
		<hr>

		<b>Date Reported: 04/09/2024 </b> <br>
		<b>Start Time:</b> 2:20 pm <br>
		<b>Work Time:</b> 2.00 hours <br>
		<ul>
			<li> I continued to assemble the packaging with new parts that were printed over the weekend. This process has been elaborated on previously so I will be brief. </li>
			<li>
				Now the upper shell is only missing on section in the front that mirrors the back. Here are the results:
				<br><img src="Team/progress/img - member4/w14i1.png" width="500" height="500" /></img> 
				<br><img src="Team/progress/img - member4/w14i2.png" width="500" height="500" /></img> 
				<figcaption>Figure 43. Images of MOUSE Packaging</figcaption>	
			</li>

		</ul>


		<hr> <h1> Week 13 </h1> <b>Hours this week: 8.00</b>  </b><hr> 

		<b>Date Reported: 04/5/2024 </b> <br>
		<b>Start Time:</b> 12:45 pm <br>
		<b>Work Time:</b> 3.00 hours <br>
		<ul>
			<li>
				I continued to construct the second half of the piece I created earlier following the aforementioned process of gorilla glueing, clamping/holding, and then hot glueing. Once I had attached it to the rest of the body, I was on backlog for the next prints to come back. I am pretty satisfied 
				with the results and feel like there could be some touch up from the hot glue later but the structure as a whole has come together nicely.
				<br><img src="Team/progress/img - member4/w13i3.png" width="500" height="500" /></img> 
				<br><img src="Team/progress/img - member4/w13i4.png" width="500" height="500" /></img> 
				<figcaption>Figure 42. Images of MOUSE Packaging</figcaption>	
			</li>
			<li>
				Trying to connect to the board, I faced an issue where the serial port was not recognized through my computer. I use a Mac with an adapter so I presumed that this could be causing
				some issues. I tried to change the port and cord configuration that I was using as well as inspect the solder to make sure there weren't any faulty connection. 
				Matt arrived at the lab shortly after this process and tried to connect with no issues so it must be something on my end. 
				We don't know the origin of this problem but as long as one of our machines work it should be sufficient for the purpose of flashing our code.
			</li>
			<li>
				I reached out to my team to determine how to progress but felt limited by the lack of physical components and inability to test software which has been my own area of expertise. We discussed the 
				merits of attempting to solder a full new board based on the things that we've learned from previous boards. Furthermore, I went to verify that the buck converter presented on our PCB matched that of
				the TI webbench files since this was our other major holdup. While I am admittedly uneducated on the intricacies of buck converters, the schematics seemed to be as expected and matched on our board. 
			</li>
			<li>
				In addition, this work session involved updating my journal and uploading relevant images.
			</li>
		</ul>
		<hr>

		<b>Date Reported: 04/4/2024 </b> <br>
		<b>Start Time:</b> 1:00 pm <br>
		<b>Work Time:</b> 1.50 hours <br>
		<ul>
			<li>Continued to build out the physical casing of the MOUSE, this time focusing on the upper layer that sits on top of the lower layer.</li>
			<li>One key thing to consider was making sure that the upper layer fit snugly on the pegs on the top of the lower layer. This involved touching up the holes
				with the dremmel and making sure that the pieces were attached precisely as intended. There is room to make the holes deeper and wider to make the connection more
				secure but the current priority was a minimum viable solution.
			</li>
			<li>
				While the process itself is not that complex, the act of sanding all pieces, glueing them together, holding them in place, and touching up with hot glue takes time to 
			ensure that connections are as tight and geometrically-sound as possible. In addition, some of the 3d printed pieces had excess pieces that needed torn away before they could be
			attached. The segment completed is shown below.
			</li>
			<br><img src="Team/progress/img - member4/w13i2.png" width="500" height="500" /></img> 
			<figcaption>Figure 41. Start to Upper Layer of MOUSE Build</figcaption>	
			
		</ul>
		<hr>

		<b>Date Reported: 04/3/2024 </b> <br>
		<b>Start Time:</b> 3:20 pm <br>
		<b>Work Time:</b> 3.00 hours <br>
		<ul>
			<li> Worked on assembly of the physical packaging including assembling the 3d-printed parts and attaching them together to complete the bottom of the MOUSE casing.</li>
			<li> One new strategy was the use of gorilla glue to add extra strength to component connections. Furthermore, sanding the points of contact made for more firm connections.</li>
			<li> Some parts of the MOUSE were not geometrically sound to clamp so I was holding them in place for 5 minutes at a time during the drying process. The final result is shown below.</li>
			<li> The design was verified to fit nicely on top of the chassis while allowing full wheel mobility.</li>
			<br><img src="Team/progress/img - member4/w13i1.png" width="500" height="500" /></img> 
			<figcaption>Figure 40. Lower Layer of MOUSE Build</figcaption>	

			<li> Additionaly responsiblities that I underwent were using the dremmel to bore holes in the upper layer of casing for the MOUSE and prepping those pieces by sanding them. Furthermore,
				I helped the team debug the connection problems that we were having with generating a successful connection to the board. Note that this was a relatively new issue that we believe arrose from 
				faulty solder connections and gpio burnouts. Part of this debugging process was conceptualizing how and why this may have occurred and we don't have an exact answer yet.
			</li>
		</ul>
		<hr>

		<b>Date Reported: 04/1/2024 </b> <br>
		<b>Start Time:</b> 2:00 pm <br>
		<b>Work Time:</b> 0.50 hours <br>
		<ul>
			<li> I didn't have a ton of time to be in the lab but I noticed that our lab station was pretty cluttered so I took time to clean and organize our workspace for further construction 
				of the physial components of our design.
			</li>
		</ul>


		<hr> <h1> Week 12 </h1> <b>Hours this week: 9.00</b>  </b><hr> 

		<b>Date Reported: 03/29/2024 </b> <br>
		<b>Start Time:</b> 5:45 pm <br>
		<b>Work Time:</b> 0.75 hours <br>
		<ul>
			<li>
				Compiled journal entries for the week and recorded them on this website.
			</li>
			<li>
				Debriefed team on my findings about how to fix the shift register problema and we started looking into solutions for modifying the board. 
			</li>
		</ul>
		<hr>

		<b>Date Reported: 03/29/2024 </b> <br>
		<b>Start Time:</b> 2:00 pm <br>
		<b>Work Time:</b> 1.00 hours <br>
		<ul>
			<li>
				Finally, I realized that the wire for the latch value was in the wrong location. When I was nudging the wires I must've been mimicing sending a latch toggle to the shift register to change the 
				values that they contained allowing the LEDs to turn on. I realized that I was correct about the SRCLR needing to be pulled high instead of low and relayed this information to the team as to 
				how the board could be fly-wired to be fixed. After this point, I was able to turn on/off one or more LED values as prescribed.
				<img src="Team/progress/img - member4/sr1.png" width="500" height="500" /></img> 
				<img src="Team/progress/img - member4/sr2.png" width="500" height="500" /></img> 
				<figcaption>Figure 39. ESP32 Shift Register Setup and LED Control Displayed</figcaption>	
			</li>
		</ul>
		<hr>


		<b>Date Reported: 03/29/2024 </b> <br>
		<b>Start Time:</b> 10:00 am <br>
		<b>Work Time:</b> 2.00 hours <br>
		<ul>
			<li>
				Finished creating the test code for the LED shift out and immediatly got feedback that the configuration was not working correctly as the lights were not turning on at all. 
			</li>
			<li>
				One improvement that I was able to make off the bat was that there was an unnecessary toggling of the latch in the loop used to create the shifted out value in the code. I was able 
				to optimize this latch toggle to only occur once after to output value was shifted out.
				<img src="Team/progress/img - member4/srcode.png" width="800" height="1000" /></img> 
				<figcaption>Figure 38. New code for shift register debugging</figcaption>	
			</li>
			<li>
				I started to mess with the SRCLR active low reset signal to make sure that it was allowing the value of the shift register to be set. After changing this to active high, one thing 
				that I noticed was if the wires were nudged then sometimes the LEDs would turn on. 
			</li>
			<li>
				Because of the seemingly random behavior that I was observing with nudging the wires, I started to mess with changing the reset value as a gpio output that was modified dynamically as the 
				code was run. However, this didn't seem to net any benefits from the previous implementation. 
			</li>
			<li>
				I continued tinkering with the various shift register input parameters with varied results, most of the time neither LED would light up.
			</li>
		</ul>
		<hr>


		<b>Date Reported: 03/28/2024 </b> <br>
		<b>Start Time:</b> 2:00 pm <br>
		<b>Work Time:</b> 1.00 hours <br>
		<ul>
			<li>
				We were experiencing an error on our board where the readings for the shift register output seemed correct but the data was not being transferred to the correct LEDs. 
				I was looking to model our schematic from our prototyping to determine what the problem was. 
			</li>
			<li>
				I started by rebuilding the circuit using the ESP32 development board that we had done a lot of prototyping on and configured the connections to the HC74595 shift register as they appeared in
				the schematic.
			</li>
			<li>
				In addition, I referenced online documentation, data sheets, and our own schematic to cross-reference and make sure that our build was correct. I setup all of the hardware in this session and 
				was starting to work on a new version of the software to control the LEDs to make sure that this was not the issue.
			</li>
		</ul>
		<hr>

		<b>Date Reported: 03/27/2024 </b> <br>
		<b>Start Time:</b> 3:30 pm <br>
		<b>Work Time:</b> 3.00 hours <br>
		<ul>
			<li>
				Discussed progress achieved by the group on soldering the board - including the entire microcontroller setup	
			</li>
			<li>
				Strategized how we were going to deal with the buck converter as we have attempted it 2 different times unsuccessfully despite taking care to use a solder mask and 
				x-ray the results until they were satisfactory. We fear that it may be a problem with the schematic itself and may have to use an external module.
			</li>
			<li>
				I verfied the integrated code by building it on the board however the corresponding behavior that we expected of the servo moving did not occur. In order to decrease the 
				number of confounding variables, we continued testing with a small version of the code that only activated the stepper. Debugging this interaction took awhile and we realized that
				the LEDs along the way were drawing too much power from the signal. The fix was to short out the LEDs and this led to success. 
			</li>
			<li>
				I spent a significant portion of time on the physical packaging of the MOUSE as I was sanding and removing hot glue that was previously used to fit the 3d-printed parts together. By sanding
				the surface, we were looking to maximize the amount of ridges that wood glue could stick to and provide a more firm base. 
				<img src="Team/progress/img - member4/chassis.png" width="500" height="500" /></img> 
				<figcaption>Figure 37. Example 3D printed MOUSE component</figcaption>	
			</li>
		</ul>
		<hr>
		


		<b>Date Reported: 03/27/2024 </b> <br>
		<b>Start Time:</b> 10:45 am <br>
		<b>Work Time:</b> 1.25 hours <br>
		<ul>
			<li>The integrated code that I created earlier was within a build environment that was configured for Matt's build configuration rather than my own. I was looking to fix parts of the integrated code 
				but was effectively coding "blind" since my build pipeline didn't allow me to build and flash the code directly. 
			</li>
			<li>
				I spent a little while researching was to resolve these build dependencies and determine if there was a way that we could both simultaneously use our code building configuration in the same shared folder. However,
				this proved to be difficult and so I moved to replicating the shared code in my own environment and then resolve builds by checking them myself.
			</li>
			<li>
				Ultimately, there were only a few minor C errors in the general function logic for the integrated code and they were easily fixed after the completion of this process. Afterward I attempted to test the 
				overall logical flow through debug mode and experienced some success.
			</li>
		</ul>


		<hr> <h1> Week 11 </h1> <b>Hours this week: 9.50</b>  </b><hr> 

		<b>Date Reported: 03/22/2024 </b> <br>
		<b>Start Time:</b> 10:00 am <br>
		<b>Work Time:</b> 2.00 hours <br>
		<ul>
			<li>
				Continued to work on analysis of patents and engaged in a more in-depth close reading of specific ideas that we could potentially infringe upon. Based on my findings, I completed the 
				the section regarding patent infringements and began final edits.
			</li>
			<li>
				Additionally, I took time to complete my journal for the week as shown here.
			</li>
		</ul>
		<hr>

		<b>Date Reported: 03/21/2024 </b> <br>
		<b>Start Time:</b> 1:00 pm <br>
		<b>Work Time:</b> 2.75 hours <br>
		<ul>
			<li>
				I met and worked with Andrew and Chris to oversee the remaining portion of soldering that needed to be completed to use the microcontroller. Upon completion, I tested the setup by 
				attempted to flash code from my computer and the result was unsuccessful - recording no serial data and suggesting that there was an issue with our soldering. We further verified that This
				was the issue by flashing code to the devboard with no issues.
			</li>
			<li>
				In an attempt to fix the buck converter, I worked with Andrew under Joe's guidance to use the heat plate on a new board in an attempt to limit the error in our design. We were
				successfully able to complete this process and the results are shown below. <br>
				<img src="Team/progress/img - member4/week11.png" width="500" height="500" /></img> 
				<figcaption>Figure 36. Showing Progress on Hot Plate Soldering</figcaption>
			</li>
			<li>
				During the down time waiting for assistance and waiting for the heat plate to heat up, I worked on combing throught the patents that we had previously identified as important
				for our initial project proposal as well as searhed for new patents that could be more relevant in accordance to the evolution of our design.
			</li>
		</ul>
		<hr>

		<b>Date Reported: 03/20/2024 </b> <br>
		<b>Start Time:</b> 3:30 pm <br>
		<b>Work Time:</b> 2.75 hours <br>
		<ul>
			<li>
				We met as a group and were reviewing the part of the board that the rest of the team had worked to solder. Part of this process was debugging and determining if part of the board that we 
				had scorched was recoverable. 
			</li>
			<li>
				Ultimately, we attempted to recover the scorched part of the board by adding a flywire and this seemed to potentially work. However, we weren't able to test it fully until the rest of the microcontroller
				system had been soldered to make sure that the desired behavior was achieved.
			</li>
			<li>
				Looked through the parts that we had from our order and looked to be able to rebuild the buck converter because we were initially unable to get it to work.
			</li>
			<li>
				Walked Matt through some of the changes that had been made to our software including the new integrated codebase that I created which combined our two sections into one.
			</li>
			<li>
				During down time I also continued to research regulations and synthesize my findings in the first part of the legal and regulatory analysis document.
			</li>
		</ul>
		<hr>

		<b>Date Reported: 03/19/2024 </b> <br>
		<b>Start Time:</b> 10:00 am <br>
		<b>Work Time:</b> 2.00 hours <br>
		<ul>
			<li>
				Started working on the document A9: Legal and Regulatory Analysis by researching regulatory agencies and determining which regulations are relevant to the MOUSE design. 
				I started to outline the key ideas that I found and determine the process for validation that would be necessary for each corresponding area of concern.
			</li>
			<li>
				This document will be worked on throughout the week and will be available in the above documents tab to view upon completion.
			</li>
		</ul>

		<hr> <h1> Week 9 </h1> <b>Hours this week: 9.00</b>  </b><hr> 

		<b>Date Reported: 03/08/2024 </b> <br>
		<b>Start Time:</b> 3:00 pm <br>
		<b>Work Time:</b> 2.00 hours <br>
		<ul>
			<li>I went back through the code and noticed a logical error that needed to be fixed - when the stop command was given the vehicle stopped sending the STBY signal, causing the robot to stop. 
				However, afterward when movement commands were enacted there was no corresponding logic to reactivate the STBY signal, allowing the motors to move freely. While I considered ways to make 
				this a one-time check, it was easier to add a function to activate the STBY signal at the beginning of each movement function. In the event that the signal is already active, I would not 
				ancipate reactivating it as having a substantial effect. 
			</li>	
			<li>
				One other idea that I realized was possible is if the microcontroller is bombarded with signals how it might respond. Additionally, if two signals are received in rapid succession with sufficient lag
				is it possible for race conditions to occur. This depended on the implementation of the socket handling function methods used in the ESPRESSIF-IDF framework. Upon researching this, it seems that these 
				event handlers are triggered sequentially, meaning that it should not require locking or other synchronization methods to operate as intended. In the end, I determined that I didn't need to preemptively 
				modify the code to fix this problem until it appears to be an issue during implementation since it could add lots of extra complexity for little return.  
			</li>
			<li>
				The rest of the time I spent trying to incorporate the soldering tactics talked about in lecture as well as grow a general familiarity with the workspace and the workflow used in soldering. I was able to practice 
				the same throughhole connections again with more success as well as attempt to solder a 64-pin ic with admittedly minimal success. However, that gave me an opportunity to try desoldering techniques as well. 
				<br>
				<img src="Team/progress/img - member4/soldering2.png" width="800" height="500" /></img> 
				<figcaption>Figure 35. Continued Progress on Soldering, Image of Through Hole, Showing Progress From Last Time </figcaption>
			</li>
		</ul>
		<hr>

		<b>Date Reported: 03/08/2024 </b> <br>
		<b>Start Time:</b> 10:00 am <br>
		<b>Work Time:</b> 2.00 hours <br>
		<ul>
			<li>I moved into integrating all of our code into one file to be used simultaneously. While most of this logic was present, a big step was laying the new motor driving modules 
				in the socket-driven portion of the microcontroller code that Matt had created. 
			</li>
			<li> One feature that I quickly realized could be helpful is the ability to set different global speed variables for different movements. For instance, turning will likely 
				occur at a different speed than when it is moving continually straight forward. Thus, I went back and changed instances of the speed variable to be more specific and thus 
				more customizable. 
			</li>
			<li>
				An additional change that I made was realizing that from a user standpoint, your orientation should be relative to the direction that you want the robot to travel rather than the 
				direction that it is already going. The solution for this was creating a new variable that actively tracks the vehicle's positon relative to the orientation that it is currently in. 
				Part of this implementation is shown below and the effect is that a user is able to press the arrow indicating the direction they want the mouse to go rather than have to anticipate the 
				relative direction of the desired direction from the orientation of MOUSE.
				<br>
				<img src="Team/progress/img - member4/switch.png" width="800" height="500" /></img> 
				<figcaption>Figure 34. Image of Nested Switch Statements using Current Orientation to Dictate Next Movement Action </figcaption>
				
			</li>
			<li>
				As a part of these feature's I also added functions to efficiently implement the logic of rotating 180 degrees and moving forward but transitioning speeds. I want the speed change to be gradual 
				enough that the handling of the MOUSE does not feel jerky. While this is not able to be tested, rudimentary measures were implemented to ease the motor through speed transitions.
			</li>
		</ul>
		<hr>

		<b>Date Reported: 03/06/2024 </b> <br>
		<b>Start Time:</b> 3:20 pm <br>
		<b>Work Time:</b>  2.25 hours <br>
		<ul>
			<li> As a team our main goal during this lab period was to finalize the PCB with the feedback we'd received, making sure that there were no remaining uncertainties before ordering.</li>	
			<li> I continued working on the new software module that I had picked up last time, being able to test that the second channel was able to run simultaneously with the first one. </li>
			<li> Tweaked the code to be more scaleable in the future, for instance I looked at the speed value and allowed it to be altered dynamically as a function parameter. This was used for 
				new movement direction functions that abstracted specific motor movements into the act of turning. While I am not able to fine-tune these movements without driving the chassis directly,
				I ran experiments on the value of the speed parameter needed to overcome the motor stall current at 5V. It was determined that this value was 130 out of the 1-byte limitation of 255. 
				<br>
				<img src="Team/progress/img - member4/enum.png" width="300" height="500" /></img> 
				<img src="Team/progress/img - member4/move.png" width="700" height="200" /></img> 
				<figcaption>Figure 32. Images of Scaling Modification to Code with Directional Enumerations as Function Arguments</figcaption>

			</li>
			<li> I ran some additional tests that included changing the direction of the wheel and its speed in succession to make sure that it operated well in these conditions. These tests were successful 
				and gave me confidence to move towards integration of all features for the final design.
			</li>
			<li> The second part of lab I spent learning the basics of soldering as I had no experience soldering before. My groupmate Chris had some experience so he demonstrated basic techniques for me. 
				I started practicing my ability to solder and was able to get a start on the process of learning the basics before our soldering lecture.
				<br>
				<img src="Team/progress/img - member4/soldering1.png" width="500" height="500" /></img> 
				<figcaption>Figure 33. Image of Progress Trying to Solder Mine are on the left (Definitely room to improve)</figcaption>

			</li>
		</ul>
		<hr>


		<b>Date Reported: 03/06/2024 </b> <br>
		<b>Start Time:</b> 1:45 pm <br>
		<b>Work Time:</b>  0.75 hours <br>
		<ul>
			<li>While I was not one of the main people in our group focused on the PCB, I wanted to make sure that we were implementing the feedback that we received from the midsemester design review presentation 
				into our design and had no glaring errors. 
			</li>
			<li>It was important for me to make sure that I combed over our board before ordering to make sure that if I had any questions that I could resolve them with the rest of the team first.</li>
			<li> Most of this time was spent taking a careful look at our design and verifying the design decisions that were already covered. There were a few questions that I brought to lab with questions about 
				why certain through-holes were used or the specific geometry used, but they were quickly resolved. 
			</li>
		</ul>
		<hr>


		<b>Date Reported: 03/05/2024 </b> <br>
		<b>Start Time:</b> 8:00 pm <br>
		<b>Work Time:</b>  1.00 hours <br>
		<ul>
			<li>I started to restructure the motor driving coding module using the base signals generated in Matt's code from the previous work session.</li>
			<li> Because these signals were working reliably, it made sense to me to create the same features that I had implemented before such as abstractions for each motor separately </li>
			<li> Additionally, the current code did not support using multiple motors simultaneously so I made sure to mirror the behavior of the first motor into the second using a new PWM channel</li>
			<li> Throughout these changes, I was able to periodically flash the code to the microcontroller and visually verify that it was working as intended to make sure that I didn't overwrite any crucial pieces 
				to the functionality of our design.
			</li>
		</ul>
		<hr>
		

		<b>Date Reported: 03/02/2024 </b> <br>
		<b>Start Time:</b> 1:00 pm <br>
		<b>Work Time:</b>  1.00 hours <br>
		<ul>
			<li> Met in the lab with Matt and Chris to help me debug the issue that I was experiencing with the integration of the motor driver with our PWM signal generation.</li>
			<li> We took a methodical approach to solving the problem, trying to identify each possible error factor and eliminate it until we discovered the root problem.</li>
			<li> At first, we thought that it could've been a problem with the motor driver's becoming burnt out by improper use, however we were able to get them working with 
				an arduino with basical signal generation.
			</li>
			<li> This led us to believe that the problem likely originated in the software, even despite proper readings of the PWM signal from an oscilloscope.</li>
			<li> Matt created a new code base that directly mimicked the behavior used in the arduino code and it worked properly, suggesting that there was some form of 
				logical error in the previous motor driving code. However, we don't know exactly what the issue was as the signals generated appear to be the same.<br>
				<img src="Team/progress/img - member4/motortest.png" width="500" height="700" /></img> 
				<figcaption>Figure 31. Image of test configuration for Motors with ESP32</figcaption>
			</li>
		</ul>

		<hr> <h1> Week 8 </h1> <b>Hours this week:</b> 9.00 </b> <br>Presentation slide deck is provided in the documents tab<hr> 

		<b>Date Reported: 03/01/2024 </b> <br>
		<b>Start Time:</b> 4:30 pm <br>
		<b>Work Time:</b>  1.50 hours <br>
		<ul>
			<li>This is the time we gave the midsemester design review presentation.</li>
			<li>The slide deck for the presentation can be found above under the documents tab.</li>
			<li>Following the presentation, I documented my progress in my notebook</li>
		</ul>
		<hr>

		<b>Date Reported: 03/01/2024 </b> <br>
		<b>Start Time:</b> 10:00 am <br>
		<b>Work Time:</b>  1.50 hours <br>
		<ul>
			<li>I practiced giving the presentation and recorded myself while doing so. Part of my preparation was reviewing the way that I spoke and making sure that I 
				didn't use filler words. In addition, I mapped out the general points that I wanted to make sure I hit to help myself have better confidence as a speaker.
			</li>
		</ul>
		<hr>

		<b>Date Reported: 02/29/2024 </b> <br>
		<b>Start Time:</b> 1:00 pm <br>
		<b>Work Time:</b>  1.00 hours <br>
		<ul>
			<li>We met together as a group and went through the entire presentation start to finish, making sure to time the overall presentation as well as the time spent 
				talking by each individual. 
			</li>
			<li>
				While building presentation skills, this run-through also allowed us to re-delegate speaking responsiblities and priorities for things we wanted to communicate. It 
				was somewhat of an art to determine which slides required more detailed explanations and which were best left at a high level.
			</li>
		</ul>
		<hr>

		<b>Date Reported: 02/28/2024 </b> <br>
		<b>Start Time:</b> 3:30 pm <br>
		<b>Work Time:</b>  2.00 hours <br>
		<ul>
			<li>During our normal lab time, our group collaborated and used the experiences we saw from peer reviewing previous presentations to look at our and make sure that all major details were included.</li>
			<li>One feature that I saw that other teams had that we didn't was the inclusion of software diagramming and a high-level architecture analysis of how they planned to implement their code. We 
				had already developed these types of diagrams and they worked well to provide context to our prototyping status slides. Part of understanding the how of software is better understanding the 
				high level overview of how everything integrates together.
			</li>
			<li>After we all felt comfortable with the slides, we broke them up into roughly equal sections and tried to prioritize each person talking about the things they were most directly involved in working on. 
			</li>
			<li>
				We were able to go through the main points that each person wanted to hit on their slides and perform rough time estimates.
			</li>
		</ul>
		<hr>

		<b>Date Reported: 02/27/2024 </b> <br>
		<b>Start Time:</b> 9:00 am <br>
		<b>Work Time:</b>  2.00 hours <br>
		<ul>
			<li>Got feedback from the rest of the team on the current slidedeck and made some modifications to the content such as adding more specification details regarding the motor drivers. 
				This specific example included adding the fact that we needed a motor driver with peak current output exceeding 1 amp to overcome the motor stall current. 
			</li>
			<li>
				A lot of the work done during this time was minor details in changing the phrasing of some slides, adding more images, and some aesthetic changes to make the overall slidedeck more 
				presentable. It is difficult to quantify these changes but the end result was that the slide deck was ready for final review by the team during our lab sections.
			</li>
		</ul>
		<hr>

		<b>Date Reported: 02/26/2024 </b> <br>
		<b>Start Time:</b> 2:00 pm <br>
		<b>Work Time:</b>  1.00 hours <br>
		<ul>
			<li>
				Continued adding to the midterm design review presentation. Specifically I worked on outlining findings from prototyping and the associated images supporting our work. 	
			</li>
			<li>
				I modified a lot of the previous descriptions within the introduction to be bulleted rather than in paragraph form. This overall should help the presentation to flow more 
				smoothly with specific key ideas highlighted rather than entire thoughts. 
			</li>
		</ul>


		<hr> <h1> Week 7 </h1> <b>Hours this week:</b> 9.00 </b><hr> 

		<b>Date Reported: 02/23/2024 </b> <br>
		<b>Start Time:</b> 1:30 pm <br>
		<b>Work Time:</b>  2.75 hours <br>
		<ul>
			<li>
				Proceeded working on motor drivers, going back to implement two PWM signals that can be modified independently. For the most part this was able to be accomplished by 
				following the same configuration of the previous motor driver, but there were some settings and special variables that I had to review documentation for such as which MCPWM unit to use. 
			</li>
			<li>
				During this process, I realized that my current code structure was not abstracted enough to make the main function simple to follow logically. I restructured a lot of the main function code into 
				different subsections. The primary goal of this is to be able to develop higher level motor driving functions that call these lower level function to create smooth movement without getting caught in 
				the weeds. I developed a new initialization function for the motor gpio pins shown below.<br> 
				<img src="Team/progress/img - member4/motor_init.png" width="500" height="700" /></img> 
				<figcaption>Figure 30. New Motor GPIO Initialization Function</figcaption>
			</li>
			<li>
				I was able to get both signals working in tandem. The image of this on the oscilloscope is shown below. 
				<img src="Team/progress/img - member4/pwm5050.png" width="500" height="400" /></img> 
				<figcaption>Figure 31. Image of Two Simultaneous PWM Signals</figcaption>
			</li>
			<li>
				Since this was working, I wanted to be able to modify the duty cycle of each function independently to simulate what would need to happen when the vehicle turns. From our model, each
				PWM signal impacts on side (either left or right) of the MOUSE and turning is conducted by slowing the motors based on a reduced PWM duty cycle on one side. When one side is faster than 
				the other, the skew causes the path of the vehicle to turn, creating the desired effect. To do this, I added speed functions for each side and tested them. Their implementation is simple but 
				powerful: they modify the duty cycle to the percentage of the value indicated by the speed variable. Below I have images of the motor speed functions and the corresponding varied duty cycle output. 
				<br><img src="Team/progress/img - member4/motor_speed.png" width="800" height="500" /></img> 
				<figcaption>Figure 32. Motor Speed Function Implementation Modifying Duty Cycle</figcaption>
				<img src="Team/progress/img - member4/pwm_mixed.png" width="500" height="400" /></img> 
				<figcaption>Figure 33. Oscilloscope Capture of Simultaneous PWM Signals with Different Duty Cycles</figcaption>
			</li>
			<li>
				One additional test that I wanted to perform to ensure that the PWM signal was able to be modified dynamically was changing the duty cycle of each signal throughout the process of the program running. 
				This was successful and performed using the following snippet of code. 
				<br><img src="Team/progress/img - member4/testduty.png" width="400" height="300" /></img> 
				<figcaption>Figure 34. Code to Dynamically Change Duty Cycle (Speed) of Output</figcaption>
			</li>
			<li>
				I completed this work session by gathering relevant images from the week and documenting my work on this website.
			</li>
		</ul>

		<hr>

		<b>Date Reported: 02/23/2024 </b> <br>
		<b>Start Time:</b> 10:00 am <br>
		<b>Work Time:</b>  1.00 hours <br>
		<ul>
			<li>Continued working on midsemester design review presentation</li>
			<li>I primarily focused on adding information for the block diagrams and component analysis sections. One key change that I made was updating our 
				block diagram to contain updates to our electrical system as well as adding power components. These additions aren't completely finalized, as I want 
				to discuss with other members of the team who have been closer to the hardware design for verification. 
				<img src="Team/progress/img - member4/blockdiagram.png" width="800" height="500" /></img> 
				<figcaption>Figure 29. Updates to Block Diagram of Electrical Components</figcaption>
			</li>
		</ul>

		<hr>

		<b>Date Reported: 02/22/2024 </b> <br>
		<b>Start Time:</b> 2:00 pm <br>
		<b>Work Time:</b>  1.00 hours <br>
		<ul>
			<li> Started adding components to our midterm design review, planning out what data each slide should contain.</li>
			<li> A big part of the midterm design review presentation is the ability to efficiently communicate information about complex systems: I made sure to go through 
				some of our previous design documents to find diagrams and charts with relevant information to help accomplish this goal.
			</li>
			<li>
				Started adding preliminary explanations of project details such as the outline and differentiating factors of other designs. 
			</li>
		</ul>

		<hr>

		<b>Date Reported: 02/21/2024 </b> <br>
		<b>Start Time:</b> 2:30 pm <br>
		<b>Work Time:</b>  3.50 hours <br>
		<ul>
			<li>
				Finished adding the gpio signals to the motor IC input ports and started software configuration for these inputs. 
			</li>
			<li>
				While testing, I was getting new errors with the PWM output as test signals on the pin outputs seemed to just generate noise. I performed a lot of debugging 
				looking at both the software and the hardware components. Some of these tests included copying out portions of code, probing the output signals, and checking other
				output signals to test if they produced a high/low output as expected. I even performed some dissassembly and reassembly of the hardware components I had created to both 
				validate the design and in hopes of it fixing this problem. 
			</li>
			<li>
				Eventually, I added a new initialization configuration of the PWM signals in my code using pwm_config instead of the brushless motor function implementation and it resulted in the signal output being restored to what I would expect. The capture of
				this signal is shown below. I am still not exactly sure why configuring the other gpio pins affected the original PWM signal that I previously had working, but this new implementation should work. I verified that the other signals were generating the 
				their expected digital output. 
				<img src="Team/progress/img - member4/pwmsingle.png" width="500" height="300" /></img> 
				<figcaption>Figure 28. Capture of Output PWM Signal </figcaption>
			</li>
			<li>
				In addition, I took advantage of the lab time as an opportunity to meet with my group members, catch up on each other's progress, collaborate on the design of the PCB, and determine next tasks and who is in charge of completing them. 
			</li>
			<li> I was not able to get the motor driver signal to pass through the motor driver IC and activate the motors in this new configuration, I will continue to work on this problem. </li>
		</ul>

		<hr>

		<b>Date Reported: 02/21/2024 </b> <br>
		<b>Start Time:</b> 10:45 am <br>
		<b>Work Time:</b>  0.75 hours <br>
		<ul>
			<li> The team changed the motor driver schematic so I modified the previously constructed circuit to model these new changes. The primary difference was chaining together the two 
				motor channels on each motor driver rather than chaining both motor drivers together with channel A on each being the same and channel B on each being the same. </li>
			<li>I also added gpio connections to the two driver input signals as well as the standby signal to be software-modifiable rather than just getting the motor to drive with PWM.</li>		
		</ul>



		<hr> <h1> Week 6 </h1> <b>Hours this week:</b> 10.75 </b> <br>Some of this weeks time was dedicated to A8 Software Formalization in the Documents tab<hr>

		<b>Date Reported: 02/16/2024 </b> <br>
		<b>Start Time:</b> 12:00 pm <br>
		<b>Work Time:</b>  1.50 hours <br>
		<ul>
			<li>
				I spent some time documenting the weeks progress on this website.
			</li>
			<li>
				I re-read the sections of the software formalization that I had drafted earlier and ensured that they were ready to be submitted. This included performing 
				final touch-ups on formatting, content, and references. I then submitted this document and uploaded it to the documents tab shown above. 
			</li>
		</ul>

		<hr>

		<b>Date Reported: 02/15/2024 </b> <br>
		<b>Start Time:</b> 10:00 am<br>
		<b>Work Time:</b> 1.00 hours <br>
		<ul>
			<li>
				I continued making progress on the A8 software formalization document, this time creating the test cases for all major project components.
			</li>
		</ul>

		<hr>

		<b>Date Reported: 02/14/2024 </b> <br>
		<b>Start Time:</b> 3:30 pm<br>
		<b>Work Time:</b> 2.25 hours <br>
		<ul>
			<li>
				Discussed features to be added and modified on schematic. Some key features include adding surge protection on motor connections, debugging leds, and planning ahead to have 
				have room for a prebuilt voltage transformer if our own implementation is not working. 
			</li>
			<li>
				Team all shared their current progress and identified features that need to be accomlished as next steps. This was primarily the IR sensor connection, PWM prototyping using the 
				ESP32 rather than an arduino, and then completing the schematic and working on the pcb design. 
			</li>
			<li>
				I worked on wiring the motor drivers to our prototyping board with our shift register and servo connections already implemented on it. The connections that I added are shown in the figure below
				and were used to create a test signal and feature microcontroller PWM from GPIO pins being passed in to drive the operating frequency.   
				<br> 
				<img src="Team/progress/img - member4/motordriver.png" width="300" height="400" /></img> 
				<img src="Team/progress/img - member4/motordriverflpd.png" width="300" height="400" /></img> 
				<figcaption>Figure 27. Images of Motor Driver Connections and Wiring</figcaption>
			</li>
			<li>
				While testing, I was performing minor tweaks to my PWM code, some of which were simple like changing the variable names to indicate whether the signal was for the left or right side motors and others were
				a bit more complex like experimenting with dynamically changing the frequency values of these driver signals to see the response.
			</li>
			<li>
				I spent a little bit of time trying to help Matt debug the IR sensing. He was able to develop a successful prototype within the main function loop but when setting up an interrupt was 
				getting finnicky results where the readings were sporadic and irregular. We tried running some tests and inserting some prints to debug, however, this was causing problems due to the 
				asynchronous nature of print trying to access the internal file buffer for stdout. Ultimately, we were unable to figure it out before I had to leave lab.
			</li>
		</ul>

		<hr>

		<b>Date Reported: 02/14/2024 </b> <br>
		<b>Start Time:</b> 2:00 pm<br>
		<b>Work Time:</b> 1.00 hours <br>
		<ul>
			<li>
				Based on our functionality we decided that we needed two independent PWM signals. Each side of the chassis will share a signal with the same wheel on its respective side. Then, 
				movement will occur by changing the frequencies of the signals on the two sides, allowing turning and fine handling. Because of this, I had to tweak some of the PWM prototyping code 
				so that it supports two distinct motor objects. 
			</li>
			<li>
				Each motor object feeds into one motor driver that is shared between the two wheels on each side using both the A and B ports. Thus, I altered the code to reflect this, creating one 
				signal per motor struct and two distinct motor structs. Shown is a portion of the modified code:
				<img src="Team/progress/img - member4/pwm_proto_code.png" width="700" height="800" /></img> 
				<figcaption>Figure 26. Multi-Motor PWM Prototyping Code</figcaption>
			</li>
		</ul>

		<hr>

		<b>Date Reported: 02/14/2024 </b> <br>
		<b>Start Time:</b> 11:00 am<br>
		<b>Work Time:</b> 2.00 hours <br>
		<ul>
			<li>
				Worked on the A8 software formalization document by defining the breakup of our software components. I made sure to note both the software implmentations that have already 
				been created as well as a few that are still to be completed. 
			</li>
			<li>
				While I worked on many areas of the document wholistically, my primary accomplishment this work session was providing a concise visual to denote the core functionality breakup of each software component that I identified. These charts are 
				shown below and on the A8 document.
				<img src="Team/progress/img - member4/A81.png" width="700" height="800" /></img> 
				<figcaption>Figure 23. Microcontroller I/O Software Overview</figcaption>
				<img src="Team/progress/img - member4/A82.png" width="700" height="800" /></img> 
				<figcaption>Figure 24. Backend Software Overview</figcaption>
				<img src="Team/progress/img - member4/A83.png" width="700" height="850" /></img> 
				<figcaption>Figure 25. Frontend Software Overview</figcaption>

			</li>
		</ul>

		<hr>

		<b>Date Reported: 02/13/2024 </b> <br>
		<b>Start Time:</b> 1:00 pm<br>
		<b>Work Time:</b> 2.00 hours <br>
		<ul>
			<li> Read extensively on documentation from Espressif on motor integration using PWM. This source reference is at this link: https://docs.espressif.com/projects/esp-idf/en/latest/esp32/api-reference/peripherals/mcpwm.html</li>
			<li> I learned a lot about not only PWM applications to motors but also that there is a distinction between brushed and brushless DC motors. For our application we are 
				using brushed motors which require less complex configuration of their control systems since they use a carbon brush rather than a rotating magnet. 
			</li>
			<li> While I had previously assumed that my code was unable to build due to not having an active microcontroller connected, I learned from talking to Matt that this was not the case for him. Thus, 
				I continued to modify my configuration files on vscode and added references to the espressif idf library specifically in the template directory that I generated for PWM. One additional note is that 
				the project was only able to build if I opened vscode specfically in this project directory, not the overarching parent directory. 
				<img src="Team/progress/img - member4/buildsuccess.png" width="550" height="300" /></img> 
				<figcaption>Figure 22. Successful PWM Code Build</figcaption>
			</li>
			<li>
				This configuration step made it easier as libraries specific to our PWM implementation were able to be linked such as bdc_motor.h which was declaring our brushed motor structs. I used these new features 
				and the documentation to alter the motor control code. 
			</li>
			<li>
				Briefly flushed out and edited some of the software component descriptions to update current team progress such as incorporation of the IR sensor rather than sonar or ultrasonic.
			</li>
		</ul>

		<hr>

		<b>Date Reported: 02/12/2024 </b> <br>
		<b>Start Time:</b> 10:00 am<br>
		<b>Work Time:</b> 1.00 hours <br>
		<ul>
			<li> I planned out the components I wanted to talk about for our A8 software formalization and drafted the outline descriptions of each component.</li>
			<li> These components ended up being: Microcontroller I/O, Recording and Playback, Sensor Data Processing, and Frontend Display</li>
		</ul>



		<hr> <h1> Week 5 </h1> <b>Hours this week:</b> 7.50 </b><hr>

		<b>Date Reported: 02/09/2024 </b> <br>
		<b>Start Time:</b> 10:00 am<br>
		<b>Work Time:</b> 2.50 hours <br>
		<ul>
			<li>
				I culminated my week's work and documentation into this website. 
			</li>
			<li>
				One action item for me during last meeting was to prototype our PWM implementation for sending a 
				signal to the motor controller. To prepare for this task, I read the overview at this link: <u>https://lastminuteengineers.com/esp32-pwm-tutorial/</u>
				as well as went through the relevant parts of the ESP-IDF Programming Guide (<u>https://docs.espressif.com/projects/esp-idf/en/latest/esp32s3/api-reference/index.html</u>).
			</li>
			<li>
				One finding that I didn't anticipate is that the ESP32 has two different PWM peripherals: one for driving LEDs and another for driving motors (MCPWM vs. LEDC). 
				I was originally planning to model the PWM signal using an LED and then translate it to the motor application but this doesn't seem practical anymore since these 
				signals have some additional features specific to their application like auto-dimming and auto-breaking respectively.
			</li>
			<li>
				When reviewing documentation, I primarily focused on the areas of gpio pins, interrupts, and PWM since these will likely 
				have the most relevance to our application. Then, I took to creating a new project with MCPWM implementation to be used with 
				our motor controller. I started from a basic MCPWM template and started to remove the elements that were unneeded for us to keep it simple
				for our first tests.
			</li>
			<li>
				I was initially planning on checking out an additional board to test PWM code on but was unable to since 
				Joe was not currently at the lab. Thus, I have developed code for PWM but haven't been able to test it yet
				when flashed on an actual hardware component.
			</li>
			<li>
				Another action that I completed was redefining our stretch PSDR #1 to include the functionality of recording and playing back movement, hopefully adding to the difficulty score of the project.
				This modification is shown on the home page and reads as follows:
				"Stretch PSDR #1 An ability to record a set path and then play back the same actions: if the robot records a path for 30 seconds, then its playback should be within 1 meter of the original pathing at all times"
			</li>
		</ul>

		<hr>
		
		<b>Date Reported: 02/07/2024 </b> <br>
		<b>Start Time:</b> 3:30 pm<br>
		<b>Work Time:</b> 2.75 hours <br>
		<ul>
			<li>
				Got feedback from instructors and team and shifted focus from the webserver to microcontroller functionality since we 
				need more development in this area. Thus, I started working with the ESPRESSIF IDF that I had started configuring in
				week 1 to help Matt who had been the primary lead in microcontroller development.
			</li>
			<li>
				I kept trying to build the existing files and had to debug a couple of errors. For one, I needed to update/install both 
				cmake and ninja for MacOS. In addition, because of the way that the files are configured in VScode, it was searching for 
				a hard-coded path specific to Matt's computer rather than my own. To solve this, I had to create my own new project and 
				initialize the configurations specific to my setup. This process seemed sub-optimal to me since it meant that code was 
				basically only able to be built and run by one person but while researching I wasn't able to find an effective fix. 
			</li>
			<li>
				We were struggling to get the sonar sensor to work at all, to the point where it wasn't even recognized by our arduino. 
				Working past this issue, we tried an ultrasonic sensor, wanting to get a sense for its accuracy and range first-hand. We 
				constructed an experiment where we set the sensor upright on a chair and moved one of the whiteboards back a measured distance,
				seeing what the corresponding reading was. There were two notable observations that I made, one of which was that the sensor seemed to 
				almost have a bimodal distribution where readings were either close to 40 in or would jump up to about 100 in. While there were
				values in between, these ranges almost seemed 'sticky'. The other key finding was that after the 100 in mark, the sensor became very 
				inconsistent at getting accurate or even just any readings. Especially considering the large size of the whiteboard, this was an alarming
				finding since range is very important for reliable movement detection in a large area such as an office space which is one of our use cases. 
				<br>
				<img src="Team/progress/img - member4/ultrasonic_test.png" width="300" height="500"/><img>
				<figcaption>Figure 21. Image of Test Setup at Max Distance of Ultrasonic Readings</figcaption>
			</li>
			<li>
				Due to these findings, we determined that another route might be best for accomplishing our motion detection with peripherals. Thus, we discussed
				the merits of using a different sensor such as infrared. However, some of these sensors would not match the rigor of implementation that rises to the 
				technical level of a PSDR. Thus, we ended up trying to determine if we should re-evaluate our PSDR's and change some of our stretch PSDRS to base PSDRS. 
				We determined that we could remove the previous PSDR involving I2C and sonar and replace it with our hardware stretch PSDR. Then, we could add the additional
				PSDR of using a servo in conjunction with the infrared module to get the range we need.
			</li>
		</ul>

		<hr>

		<b>Date Reported: 02/05/2024 </b> <br>
		<b>Start Time:</b> 11:30 am<br>
		<b>Work Time:</b> 1.50 hours <br>
		<ul>
			<li>I ended up hurting my hand pretty significantly, limiting my ability to type and document efficiently. This 
				ended up significantly slowing my progress the rest of this week.
			</li>
			<li>
				I worked on the dynamic display of the recording and playback states of our design. The solution that I came up
				with involved creating new socket endpoints to specifically communicate this status data whenever a change occurs.
			</li>
			<li>
				One of the biggest issues that I faced was that the dashboard was seemingly unresponsive. However, after a decent bit
				of debugging I realized that I was connected to the remote server rather than my local one, causing my changes to not be
				visible. This was a silly mistake and one I will be sure to be more careful about in the future. 
			</li>
			<li>
				I was able to get the feature working and the buttons now hold their 'pressed' color when their mode is active. One key step was 
				making sure that I had covered all possible state changes so that the state variables matched the current state. If one is missing, 
				then the entire system becomes out of sync and the frontend does not model the backend correctly. I tried to 
				break it by rapidly pressing multiple different buttons as well as the recording and playback buttons at the same time but it
				held up robustly through this testing.
			</li>
		</ul>

		<hr>

		<b>Date Reported: 02/04/2024 </b> <br>
		<b>Start Time:</b> 5:00 pm<br>
		<b>Work Time:</b> 0.75 hours <br>
		<ul>
			<li>Researched how to use CSS to give user feedback when pressing buttons on frontent. Was 
				able to successfully implement this feature to change the button color on click. 
				<br>
				<img src="Team/progress/img - member4/active_button.png" width="400" height="300"/></img>
				<figcaption>Figure 20. Image of Dynamic Button Feedback on Click</figcaption>
			</li>
			<li>
				Similarly to how to dynamically show the microcontroller connection status, I also wanted to 
				add a feature that shows when the MOUSE is actively in the recording or playback modes. This implementation
				gave us significant trouble last time and we ultimately had to use our textfile to store data and read it back 
				to the frontend. Since this seemed inefficient, I mapped out a way to implement this using local variables to be 
				put in place next work session.
			</li>
		</ul>
		
		<hr> <h1> Week 4 </h1> <b>Hours this week:</b> 10.25 <hr>
		<b>Date Reported: 02/02/2024 </b> <br>
		<b>Start Time:</b> 1:15 pm<br>
		<b>Work Time:</b> 2.75 hours <br>
		<ul>
			<li>Formalized documentation from my notes and saved images into the finalized version on this webpage</li>
			<li>
				Thought about the current use cases for the playback button and realized that it made the most sense to model the playback button structure in the same way that the recording was done with 
				one button that triggered a repeated action and then another to stop. So, in the case of the playback button, the original button was repurposed to always loop the outputs of the recording
				until the user triggers a stop manually. In addition, a new button was added to trigger the stopping of the playback.
			</li>
			<li>
				One potential issue that I was able to foresee was the user entering a state in which they are both recording and trying to play back input at the same time. Not only would this introduce a lot of 
				conflict in accessing and modifying the same resources simultaneously, even if behaved properly it would not contribute to the core functionality in any practical way. Thus, I implemented a checking 
				procedure in each of the function calls to alert the user and abort action whenever recording and playback were active simultaneously. This involved manipulating a new boolean global variable called
				playback that indicates if the playback function is active. 
				<br>
				<img src="Team/progress/img - member4/playback_record_err.png" width="900" height="300"/></img>
				<figcaption>Figure 19. Displays the New Alert For Simultaneous Recording and Playback, also Features Most Recent Button Layout</figcaption>
			</li>
			<li>
				The biggest challenge that I tackled this session was in the form of modifying the original playback function to be able to loop repeatedly. While I anticipated that this 
				would be an easy task - just putting the code in a while loop, this did not end up working since it caused gridlock in the asynchronous function calls. In order to get the 
				implementation that I wanted, I determined that a possible solution was recursively calling a function that performs the playback rather than looping. This was quite complex 
				to execute on syntactically as I am not the most experienced javascript programmer but I was able to get it to work. An additional optimization that I made was only loading the 
				contents of the recording file once before the recursive calls. Lastly, I also wanted a way to break out of the playback as soon as the 'stop playback' button had been pressed. 
				This was accomplished by nesting calls to break out of the function early or prevent the calling of itself if the global flag for playback became unset. The resulting code is shown below. 
				<br>
				<img src="Team/progress/img - member4/playback_loop.png" width="700" height="1000"/></img>
				<figcaption>Figure 20. New Playback Logic for Handling Looping and Stop Interruptions</figcaption>
					
			</li>
			<li>
				All of these components contribute to the goal of achieving recording and playback which add an additional layer of functionality (and complexity) to the project.
			</li>
		</ul>

		<hr>

		<b>Date Reported: 01/31/2024 </b> <br>
		<b>Start Time:</b> 3:30 pm<br>
		<b>Work Time:</b> 2.00 hours<br>
		<ul>
			<li>Perfomed analysis and formalized final design decisions for core components to complete our component analysis. A particular area of interest to me was the choice between 
				ultrasonic, sonar, and lidar sensors to perform scanning and provide data for alert detection. We ultimately settled on using sonar sensors and establishing lidar as a stretch
				functionality that could cross-check our results if we have time. This would make the overall detection algorithm more robust and resistive to errant readings. More of this document
				can be seen in the team documents tab at the top of this page. 	 
			</li>
			<li>
				Planned the next steps in software and microcontroller development. Worked with Matt to determine how we could continue to integrate the webserver and the microcontroller to 
				achieve our PSDRs relating to movement and playback. We devised a plan consisting of the following action items: creating a manual stop button, adding a loop option to the playback
				feature so that recordings can be played indefinitely, and making a free-drive mode where the robot will move freely without attempting to stop and scan as well as an alert mode where 
				the robot will periodically stop, scan, report results, and keep moving on the same path. 
			</li>
		</ul>	
	
		<hr>

		<b>Date Reported: 01/30/2024 </b> <br>
		<b>Start Time:</b> 10:50 pm<br>
		<b>Work Time:</b> 3.00 hours<br>
		<ul>
			<li>
				Noticed an error where the notifications on our server for date/time alert triggering were off by 5 hours. I was able to solve this by adding specific locale information
				for EST. Additionally, cleaned up the output to print without extra commas by parsing the data before it went to the output. 
				<br>
				<img src="Team/progress/img - member4/detectionwarning.png" width="500" height="250"/></img>
				<figcaption>Figure 14. Output Cleanup for Mouse Alerts (note that image was taken later but results unmodified)</figcaption>
			</li>
			<li>
				Continued to implement the movement recording functionality and encountered several errors where file reads in both the recording and general led/direction storage were resulting in parsing of null data.
				I was able to fix this issue by adjusting the parsing algorithm as there was a typo where a space was actually supposed to be a '|' character. This error is captured below.
				<br>
				<img src="Team/progress/img - member4/readerr.png" width="500" height="250"/></img>
				<figcaption>Figure 15. Error in Reading From Record Files</figcaption>
			</li>
			<li>
				After I fixed the error, I was able to successfully record and validate the reading of inputs using the record button from the mouseui page. This allowed me to move into the callback feature.
			</li>
			<li>
				When attempting to implement specific time-delays between function calls, I learned a lot about the call structure that javascript uses. Since most of the calls are ultimately executed in an 
				asynchronous fashion, my intial attempt at playback was unsuccessful. As shown below, my implementation of the playback functionality set timeouts but they were each called and run in parallel, 
				creating a race condition for the order in which the directional data was sent to the microcontroller. This was a big problem and is shown in a sample output. 
				<br>
				<img src="Team/progress/img - member4/playback_wrong.png" width="500" height="300"/></img>
				<figcaption>Figure 16. Incorrect Implementation of Playback - Executes Asynchronously</figcaption>
				<br>
				<img src="Team/progress/img - member4/race_cond.png" width="300" height="500"/></img>
				<figcaption>Figure 17. Example of Race Condition Output - Results Don't Match Order</figcaption>

			</li>
			<li>
				In order for the playback feature to work correctly, I needed the calls to each entry in the recording table to be executed sequentially, blocking for the next call to be made. In order to achieved
				this in javascript, I found that the 'promise' feature could be used to force this behavior by establishing a wait for each promise to finish before executing the next one. This took a decent amount of 
				experimentation but I eventually came up with a structure that worked effectively. When testing, I intentionally delayed and changed the sequence of inputs and was able to successfully play them back in
				a similar timing to how they were received. The final implementation of the playback code is shown below. This addition is key to advancing our stretch functionality of being able to record a set path and 
				play it back for the robot to be able to monitor a nearby area continuously. 
				<br>
				<img src="Team/progress/img - member4/playback_right.png" width="500" height="600"/></img>
				<figcaption>Figure 18. Working Playback Code - Features Forced Waits on Asynchronous Calls</figcaption>
			</li>
		</ul>
		<hr>

		<b>Date Reported: 01/30/2024 </b> <br>
		<b>Start Time:</b> 3:00 pm<br>
		<b>Work Time:</b> 1.00 hours<br>
		<ul>
			<li>Spent time incorporating new buttons to emulate the design construct that I had previously outlined in the block diagram. The basics of this structure include
				handling the global variable 'recording' to determine when to record inputs, recording the time that this action occurred, writing the data and time to a log file,
				and reading this data when playback is initiated. 
			</li>
			<li>
				Workshopped but was ultimately unsuccessful in devising a system where instead of having an absolute time each written record entry has only the elapsed time between
				that command and the previous command. However, due to the many potential process flows, this was not feasible to implement efficiently as the original initial time would 
				have to be recorded and maintained globally which introduced multiple new potential errors. Instead, I maintained the simplicity of the previous absolute-time method.
			</li>
			<li>
				I started working on the node backend endpoints to record data tables into a text file as they are enacted on the MOUSE homepage. Below is a sample of the output file.
				This operation is the start of the implementation of the entire recording and playback process which I will continue to work on. 
				<br>
				<img src="Team/progress/img - member4/recordingfile.png" width="400" height="300"/></img>
				<figcaption>Figure 13. Data Storage in Recording.txt File for Recording/Playback Feature</figcaption>
			</li>

		</ul>

		<hr>

		<b>Date Reported: 01/29/2024 </b> <br>
		<b>Start Time:</b> 9:10 pm<br>
		<b>Work Time:</b> 1.50 hours<br>
		<ul>
			<li> Spent some time adding the buttons to support recording and playback features on the frontend as well as the corresponding backend socket endpoints to be 
				able to trigger events. 
				<br>
				<img src="Team/progress/img - member4/rcd_buttons.png" width="300" height="250"/></img>
				<figcaption>Figure 10. Image of Recording and Playback Buttons on Frontend</figcaption>
				<br>
				<img src="Team/progress/img - member4/rcd_plbck_back.png" width="400" height="300"/></img>
				<figcaption>Figure 11. Image of Code Recording Button Presses</figcaption>
			</li>	
			<li>
				Researched general recording and playback methods in javascript. I had originally planned to use threading and barriers to synchronize the playback but determined that this was not a
				feature that is directly incorporated in javascript. Instead, a time-stamp based approach was found to be effective and could be more robust as it does not require determination of a 
				a constant delay for each directional input.
			</li>
			<li>
				While a time-stamp-based approach would increase the total amount of data stored per each input (requires both direction and timestamp rather than just direction), this approch makes the
				memory complexity based on the number of inputs (direction/timestamp entries) rather than on the amount of total time it takes to record the route (where each entry has an implicit time differential).
				Based on this application of directing a robot along a security path, making this complexity be reliant on inputs rather than time is likely to be much more efficient.
			</li>
			<li> I diagramed the general timing behavior that I wanted to create in this implementation
				<img src="Team/progress/img - member4/rcd_brainstorm.png" width="900" height="700"/></img>
				<figcaption>Figure 12. Drafting the Logic of the Recording and Playback Feature</figcaption>
			</li>
		</ul>


		<hr> <h1> Week 3 </h1> <b>Hours this week:</b> 9.00 <hr>


		<b>Date Reported: 01/26/2024 </b> <br>
		<b>Start Time:</b> 11:00 am<br>
		<b>Work Time:</b> 1.00 hours<br>
		<ul>
			<li>
				Resolved the issue where the microcontroller status was not updating correctly by simplifying the node api to just send message on connect and disconnect rather
				than have the frontend attempt to repeatedly fetch data regarding the microcontroller status. This approach is much less computing-intensive than what was previously used.
			</li>
			<li> I started researching ways to process datastreams to detect movement. One such research topic that intrigued me was the notion of a Kalman filter. Based on my findings
				a Kalman filter provides a way of processing data to filter our error and measure uncertainty to create a strong prediction of the actual process state. In this case, that 
				would be the assessment of whether movement was detected via velocity calculations found through processing time-dependent distance readings. 	
			</li>
			<li>
				Next steps with this information are to incorporate a specific software-implementation of this type of filtering, however at this point in development there are 
				a variety of factors that may change such as how we are getting the data input, what type of sensor readings we get, and what processing is done via the micro vs
				the webserver. Since these are subject to the testing of our sensors that have yet to arrive, I am wary to make too many assumptions about what this algorithm should look like yet.
			</li>
			<img src="Team/progress/img - member4/kalmanfilter.png" width="500" height="250"/></img>
			<figcaption>Figure 9. Sample diagram of a Kalman filter</figcaption>
			<figcaption>Refence: https://www.researchgate.net/publication/235421822_Adaptive_filters_and_internal_models_Multilevel_description_of_cerebellar_function</figcaption>
		</ul>	

		<hr>

		<b>Date Reported: 01/25/2024 </b> <br>
		<b>Start Time:</b> 1:20 pm<br>
		<b>Work Time:</b> 1.50 hours<br>
		<ul>
			<li>Spent some time learning how to apply css to vue components and applications into conditional rendering of components. The primary inspiration of this was to 
				be able to include a button that showed red when the microcontroller was disconnected and green when there was a connection. This was able to be accomplished  
				and allowed me to practice creating data-driven display since I had never been exposed to this type of development before.
			</li>
			<li>Made the dashboard centered on the screen and incorporated a more aesthetically-pleasing button layout with directional triangles indicating 
				the different directional buttons to travel. I tested to make sure that these changes preserved the existing button functionality. While not
				exceptionally complicated, these changes help progress PSDR 4 which indicates an ability to effectively display data and control features.
			</li>
			<img src="Team/progress/img - member4/mouseui.png" width="500" height="250"/></img>
			<figcaption>Figure 8. New UI for MOUSE homepage</figcaption>
		</ul>	

		<hr>

		<b>Date Reported: 01/24/2024 </b> <br>
		<b>Start Time:</b> 3:30 pm<br>
		<b>Work Time:</b> 2.50 hours<br>
		<ul>
			<li>Updated teammates on the new socket schema and assisted with configuration of the current microcontroller message structure to meet compliance with the new standard.</li>
			<li>Tested server-latency of pressing directional buttons to make sure reasonable control of the robot could be achieved.</li>
			<li>Went through code and added additional logging messages to help debug connectivity problems in communication between webserver and microcontroller</li>
			<li>Implemented a new command to fetch and return the status of the microcontroller connection from the frontend. The goal with this command was to implement a new
				part of the display indicating whether or not an active microcontroller connection was achieved. Not only is that is valuable tool for testing, it is also a good
				quality-of-life feature that is essential to making the dashboard accessible for a product owner.
			</li>
			<li>I was running into a few issues where the frontend code was trying to read from the socket before it was established, causing errors. Some potential fixes were 
				implementing an additional wait call to make sure that the connection was already established. However, the end result was still bugged as the display only showed 
				the microcontroller status as disconnected. This is something I will continue to work on.
			</li>
		</ul>

		<hr>

		<b>Date Reported: 01/24/2024</b> <br>
		<b>Start Time:</b> 12:00 pm<br>
		<b>Work Time:</b> 2.00 hours<br>
		<ul>
			<li>Since the socket stream would need to be capable of receiveing both commands and data, I formalized a message schema to allow 3-way communication between 
				the Vue frontend, Node backend, and ESP32 microcontroller. 
			<img src = "Team/progress/img - member4/msg_schema.png" width="400" height="150"/></img>	
			<figcaption>Figure 7. Overview of message schema</figcaption>
			</li>
			<li>In order to recognize and process these commands when recieved, I developed a basic message parsing system using regex matching to capture both the 'command'
				and the 'data' portions of the message (if data is present in the command). This message framework was designed with the ability to add functionality later 
				for additional features and messages including large amounts of data to be processed. 
			</li>
			<li>
				Another key feature that I was able to implement was a function that triggered an alert message when movement was detected, recording and displaying the date and time of the detection. While there isn't any movement data yet,
				I tested just the alert by itself and it was successfully able to broadcast to all client connections simultaneously. 
			</li>
		</ul>	

		<hr>

		<b>Date Reported: 01/22/2024</b> <br>
		<b>Start Time:</b> 8:20 pm<br>
		<b>Work Time:</b> 2.00 hours<br>
		<ul>
			<li>Updated the backend code to work with socket connections instead of hitting defined endpoints, this involved changing the existing endpoints into commands read from the socket
				stream each time a new message was read. This was done to reduce latency when sending and receiving directional inputs from the microcontroller. I was able to recover all previously 
				demonstrated capabilities implemented as endpoints. 
			</li>
			<li>
				I introduced a client monitoring system that classified and stored each connection type within the app's node api. This implementation keeps a log of all of the active connections, allowing
				notification of how many connections and of what type are accessing the webclient simultaneously. This is essential to implmenting our PSDRs 4 and 5 as the webserver needs to be able 
				to store and directly message the microcontroller connection to keep low latency in vehicle control. In addition, the core functionality of our design as a security robot is implemented 
				through the ability to broadcast messages (such as security alerts) to all connected clients for monitoring.
			</li>
			<img src = "Team/progress/img - member4/client_connections.png" width="600" height="200"/></img>
			<figcaption> Figure 6. Displays monitoring of client connections on Node backend </figcaption>
		</ul>


		<hr> <h1> Week 2 </h1> <b>Hours this week:</b> 9.00 <hr> 
		<b>Date Reported:</b> 01/18/2024 <br>
		<b>Start Time:</b> 10:30 am <br>
		<b>Work Time:</b> 2.00 hours <br>
		<ul>
			<li>Continued learning about the basics of Vue.js using <u>https://vuejs.org/guide/introduction.html</u></li>
			<li>Created directional buttons on our webpage to be used in controlling the robot from the webserver</li>
			<li>Added the vue functions to be called when button events were triggered for each of the four directions. These additions are pictured: </li>
			<img src = "Team/progress/img - member4/directional_buttons.png" width="600" height="200"/></img>
			<figcaption> Figure 5. Rudimentary controls page with directional buttons </figcaption>
			<li>Added corresponding endpoints in our api for vue to interface with. The end result was two api calls for each button press:
				one going from Vue to the main app.js and then app.js sends data to the microcontroller (not yet implemented)
			</li>
			<li>During this process, I also learned how to use npm to test the frontend development locally as well as node to test the api. However, I 
				had a hard time getting local testing of the api to work so I am continuing to learn in that area.
			</li>
		</ul>
		<hr>

		<b>Date Reported:</b>01/17/2024<br>
		<b>Start Time:</b> 3:30 pm <br>
		<b>Work Time:</b> 2.25 hours <br>
		<ul>
			<li>Laid out the basics of block diagram for chassis and microncontroller interfacing, discussing them with the team and making modifications until we agreed on a vision for our product. I created this block diagram to model our system interconnects
				<img src="img/description-block-diagram.png" width="388.33" height="281.33"/></img>
				<figcaption> Figure 4. Block diagram of the hardware/mechanical system components</figcaption>

			</li>
			<li>Collaborated with the team to make our PSDRs more specific and concise to further direct our design focuses. During this discussion, we reassessed the functional capabilities that we
				wanted to see in the final design. This involved making some features stretch goals such as the recording and playback of movement patterns for autonomous movement.
			</li>
			<li> Additionally, I focused on researching some of the enviromnental hazards and durability requirements that may dictate the use cases of our security robot. The MOUSE should be fairly durable
				and not too big that it becomes difficult to transport as this would make it much harder for a customer to use. They should be highly durable as we expect them to constantly be running overnight
				and to last for at least a year to be something that people are willing to buy.
			</li>
			<li>I worked alongside Andrew to debug the shift registers in his prototype for showing battery diagnostics. This was done using an arduino and we were having an issue where the first two arrays
				of LEDS worked as expected but the final was not lighting up. After some debugging, we determined that rebuilding the circuit on a new board was worthwhile and ended up fixing the issue later that day.
				</li>
		</ul>

		<hr>

		<b>Date Reported:</b>01/16/2024<br>
		<b>Start Time:</b> 12:00 pm <br>
		<b>Work Time:</b> 1.50 hours <br>
		<ul>
			<li>Discussed pros and cons of existing server setup with the rest of my teammates. Whenever the server would crash (which it did a few times) we would have to reboot it which generated a new ip address. 
				this meant than the code had to be modified each time this occurred to include the new ip which was tedious and prevented members from accessing the server. I originally planned to create a batch script that
				could scrape AWS to get the ip of the server and insert it into our code dynamically, however AWS already had a better built-in solution in elastic ips. By configuring and connecting an elastic IP to our existing
				EC2 instance, I was able to solve this problem and maintain a static ip through server restart. 
			</li>
			<li>Once the new configured was up and running, I created basic bash scripts to access the server and test endpoints more easily to help us in development of the webserver-controlled elements of our design as required by one of our PSDRs.
				<img src = "Team/progress/img - member4/endpointscript.png" width="600", height="300"> </img>
				<figcaption> Figure 3. A bash script for endpoint testing</figcaption>
			</li>
		</ul>
		<hr>
		
		<b>Date Reported:</b>01/16/2024<br>
		<b>Start Time:</b> 9:30 am <br>
		<b>Work Time:</b> 1.50 hours<br>
		<ul>
			<li>Got access to repo and cloned locally for devleopment</li>
			<li>Configured local neovim setup to include support for html, css, javascript, vue, and json. This was done by adding lsp support through mason in my lua config files and will help streamline server-side development. </li>
			<li>Continued to familiaze myself with the existing test configuration on the nginx webserver as I hadn't been exposed to a javascript server like this before. In order to add to my understanding, I checked the active endpoints and my own sample test endpoint and validated that they worked.</li>
		</ul>
		<hr>

		<b>Date Reported:</b>01/15/2024<br>
		<b>Start Time:</b> 2:00pm<br>
		<b>Work Time:</b> 1.75 hours<br>
		<ul>
			<li> Read documentation and configured my development environment for ESP32 using Matt's documentation on espressif. Spent time learning the build process as well as debugging mac-related dependencies.</li>
			<li> Established connection to the EC2 instance in our AWS server using our key. </li>
			<li> Met with Matt to overview the existing setup containing an api interfacing with the microcontroller we are testing on. Additionally, went over front-end layout and user login caching schema</li>
			<li> Started reading Vue.js documentation and went through a crash course on JavaScript syntax to prepare to work on the software side of our project</li>
		</ul>

		<hr> <h1> Week 1 </h1> <b>Hours this week:</b> 3.50 <hr> 

		<b>Date Reported:</b> 01/12/2024-<br>
		<b>Start Time:</b> 10:00am<br>
		<b>Work Time:</b> 1.00 hours<br>
		<ul>
			<li> Consulted group about our software requirements and worked on developing diagram to define systems components and plan ahead for integration efforts. We ended up settling on hosting an EC2 instance on AWS to serve a webpage and api for the MOUSE to interact with. 
				These design choices are means of accomplishing PSDRs 4 and 5 as both of them will be deployed to this host and need to be able to effectively send and receive http requests from the user and MOUSE.
			</li>
			<img src="Team/progress/img - member4/SoftwareSystem.png" class="picture"> </img> 
			<figcaption> Figure 2. System Software Block Diagram</figcaption>
		</ul>
		<hr>

		<br></br>
		<b>Date Reported:</b> 01/10/2024<br>
		<b>Start Time:</b> 3:30pm<br>
		<b>Work Time:</b> 2.50 hours<br>
		<ul>
			<li>Collaborated with teammates to better define project requirements and desired features for development. Considered and researched the feasiblity of utilizing an ESP32 microcontroller to interface with motors/sensors/diagnostics/webservers. Used this knowledge to initialize the bill of materials for the project and start to perform initial cost analysis. I was focused on the differences between using lidar and ultrasonic sensors for our motion detection and their interfacing with the hardware. Some of the options that I found include a 360 degree lidar sensor and ultrasonic sensors. 
				The lidar sensors were found to be more costly, between $50 and $100 whereas the ultrasonic sensors were cheaper at around $10 for a pack of multiple sensors. These design components are essential to our core functionality of detecting motion and our PSDRs 3 and 4 which involve collecting and displaying this sensor data.  </li>
			<li>Here is a website I found demonstrating ultrasonic sensor connection to an ESP32: <u>https://randomnerdtutorials.com/esp32-hc-sr04-ultrasonic-arduino/</u> </li>
			<li>This is the image of the lidar sensor that I found: 
				<img src="Team/progress/img - member4/lidar_sensor.png" width="600" height="400"></img>
				<figcaption> Figure 1. Lidar Sensor Image</figcaption>
			</li>
		</ul>
		<!-- 
		<b>Date Reported:</b> -Enter the date for this journal entry mm/dd/yyyy (the date the project meeting or work was performed)-<br>
		<b>Start Time:</b> -Enter the time you began the meeting/work for this entry e.g., 2:37pm-<br>
		<b>Work Time:</b> -Enter how long the meeting or work lasted for this entry (round to nearest quarter hour) e.g., 1.25 hours-<br>
		-Discuss your project meeting/work for this entry here. Make sure that this is from your individual perspective and include images, video, and other graphics.  Follow the guidelines presented in the Progress Report Policy that is posted on Brightspace.  This is a template entry; simply copy/paste this entry and overwrite for each journal entry.-  </br>
		-->

		<!-- Instantiate global footer. Any changes to the footer should be made through the top-level file "footer.html" -->
		<div id="footer"></div>
    </div>
</div>

<!--JS-->
<script src="js/jquery.js"></script>
<script src="js/jquery-migrate-1.1.1.js"></script>

<script type="text/javascript">
$(document).ready(function() {
    $("#header").load("header.html");
	$("#menu").load("navbar.html");
	$("#footer").load("footer.html");
});
</script>
</body>
</html>
